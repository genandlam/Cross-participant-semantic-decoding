{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40d85f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ckj24/miniforge-pypy3/envs/fmri-algo/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ckj24/miniforge-pypy3/envs/fmri-algo/lib/python3.13/site-packages/torch/__init__.py:1240: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:434.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import config, consts, paths\n",
    "from decoding.GPT import GPT\n",
    "from decoding.utils_stim import get_stim\n",
    "from decoding.utils_resp import get_resp_test\n",
    "from decoding.StimulusModel import LMFeatures\n",
    "from encoding.ridge import ridge, bootstrap_ridge\n",
    "from utils import flatten_list, save_data\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e15523a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject='UTS09'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e381f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_serializable(downsampled_feat):\n",
    "    \"\"\"Convert downsampled feature dictionary to a serializable format.\"\"\"\n",
    "    \n",
    "    serializable_dict = downsampled_feat.tolist()\n",
    "\n",
    "    return serializable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97eefa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(stories, subject):\n",
    "\t\"\"\"Get the subject\"s fMRI response for stories.\"\"\"\n",
    "\t#main_path = pathlib.Path(__file__).parent.parent.resolve()\n",
    "\tsubject_dir = os.path.join(config.DATA_DIR, \"derivative/preprocessed_data/%s\" % subject)\n",
    "\tbase = subject_dir\n",
    "\tresp = []\n",
    "\trun_on_set = []\n",
    "\tfor story in stories:\n",
    "\t\tresp_path = os.path.join(base, \"%s.hf5\" % story)\n",
    "\t\thf = h5py.File(resp_path, \"r\")\n",
    "\t\tresp.extend(hf[\"data\"][:])\n",
    "\t\tif not run_on_set:\n",
    "\t\t\trun_on_set.append(hf[\"data\"][:].shape[0])\n",
    "\t\telse:\n",
    "\t\t\trun_on_set.append(run_on_set[-1]+hf[\"data\"][:].shape[0])\n",
    "\t\t#print(hf[\"data\"][:].shape[0], \"for story:\", story)\n",
    "\t\thf.close()\n",
    "\treturn np.array(resp), run_on_set[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a282455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gpt\n",
    "stories = flatten_list(consts.STORIES)\n",
    "stories_t =consts.STORIES_test\n",
    "with open(os.path.join(config.DATA_LM_DIR, \"perceived\", \"vocab.json\"), \"r\") as f:\n",
    "    gpt_vocab = json.load(f)\n",
    "gpt = GPT(path = os.path.join(config.DATA_LM_DIR, \"perceived\", \"model\"), vocab = gpt_vocab)\n",
    "features = LMFeatures(model = gpt, layer = config.GPT_LAYER, context_words = config.GPT_WORDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccd861ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate noise model\n",
    "num_voxels = consts.NUM_VOXELS[subject]\n",
    "rstim, tr_stats, word_stats = get_stim([stories_t], \"story\", features)\n",
    "alphas = np.zeros(num_voxels)\n",
    "bscorrs = np.zeros([len(config.ALPHAS), num_voxels, config.NBOOTS])\n",
    "voxels = np.sort(np.argsort(bscorrs)[-config.VOXELS:])\n",
    "#splits = np.array_split(range(num_voxels), 2)\n",
    "weights = np.zeros([rstim.shape[1], num_voxels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cca95d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 3072)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rstim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0c97876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 98336)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zRresp_t = get_resp_test(subject)\n",
    "zRresp_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23768dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1869, 98336)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zRresp,run_on_set = get_response(stories, subject)\n",
    "zRresp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ce840ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[343, 698, 1065, 1465]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_on_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd5d43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location=os.path.join(paths.EM % subject)\n",
    "#os.makedirs(save_location, exist_ok=True)\n",
    "#with open(save_location+'/run_on.json', \"w\") as file:\n",
    "#    json.dump(run_on_set,file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd45a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(save_location+'/fmri_train.json', \"w\") as file:\n",
    "#        json.dump(convert_to_serializable(zRresp),file, indent=4)\n",
    "#with open(save_location+'/features_train.json', \"w\") as file:\n",
    "#        json.dump(convert_to_serializable(rstim),file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c2772a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_location=os.path.join(paths.EM % subject)\n",
    "with open(save_location+'/fmri_test.json', \"w\") as file:\n",
    "        json.dump(convert_to_serializable(zRresp_t),file, indent=4)\n",
    "with open(save_location+'/features_test.json', \"w\") as file:\n",
    "        json.dump(convert_to_serializable(rstim),file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri-algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
