{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ea30019",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'encoding.stimulus_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdecoding\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils_stim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_wordseqs, get_roi_features\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdecoding\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils_resp\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_resp\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mencoding\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDataSequence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataSequence\n",
      "File \u001b[0;32m~/Documents/GitHub/Cross-participant-semantic-decoding/decoding/utils_stim.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mencoding\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstimulus_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TRFile, load_textgrids, load_simulated_trfiles\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mencoding\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdsutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_word_ds, make_semantic_model\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mencoding\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lanczosinterp2D\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'encoding.stimulus_utils'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "import config\n",
    "from decoding.utils_stim import get_wordseqs, get_roi_features\n",
    "from decoding.utils_resp import get_resp\n",
    "from encoding.DataSequence import DataSequence\n",
    "from encoding.util import make_delayed\n",
    "from encoding.ridge import bootstrap_ridge\n",
    "from utils import flatten_list, save_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df35bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject= ''\n",
    "save_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "stories = flatten_list(consts.STORIES)\n",
    "wordseqs = get_wordseqs(stories, \"story\")\n",
    "with open(os.path.join(config.DATA_TRAIN_DIR, \"ROIs\", f\"{subject}.json\"), \"r\") as f:\n",
    "    roi_voxels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d106f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features\n",
    "resp_full = get_resp(subject, stories, \"story\", stack = True)\n",
    "resp_roi, tr_stats = get_roi_features(resp_full, roi_voxels, consts.ROI)\n",
    "del resp_full\n",
    "delresp = make_delayed(resp_roi, config.RESP_DELAYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72340e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target\n",
    "rates = {}\n",
    "for story in stories:\n",
    "    ds = wordseqs[story]\n",
    "    words = DataSequence(np.ones(len(ds.data_times)), ds.split_inds, ds.data_times, ds.tr_times)\n",
    "    rates[story] = words.chunksums(\"lanczos\", window = 3)\n",
    "nz_rate = np.nan_to_num(np.concatenate([rates[story][5+config.STRIM:-config.STRIM] for story in stories], \n",
    "        axis = 0).reshape([-1, 1]))\n",
    "mean_rate = np.mean(nz_rate)\n",
    "rate = nz_rate - mean_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29353344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# estimate word rate model\n",
    "weights, _, _ = bootstrap_ridge(delresp, rate, alphas = config.ALPHAS_WR, nboots = config.NBOOTS, \n",
    "        chunklen = config.CHUNKLEN, use_corr = False, seed = 42)\n",
    "wr_decoder = dict(zip(['weights', 'mean', 'rois', 'stories', 'tr_stats'], \n",
    "        [weights, mean_rate, consts.ROI, stories, tr_stats]))\n",
    "save_data(save_dir, wr_decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naturalistic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
