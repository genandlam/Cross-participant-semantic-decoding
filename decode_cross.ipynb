{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b487f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/naturalistic/lib/python3.12/site-packages/torch/__init__.py:1264: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:436.)\n",
      "  _C._set_default_tensor_type(t)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "from utils import flatten_list, save_data\n",
    "import config, consts, paths\n",
    "from encoding.ridge import bootstrap_ridge\n",
    "from decoding.StimulusModel import StimulusModel, get_lanczos_mat, affected_trs, LMFeatures\n",
    "from decoding.utils_stim import predict_word_rate, predict_word_times\n",
    "from decoding.utils_resp import get_resp, get_resp_test\n",
    "from utils import nsort, flatten_list\n",
    "from decoding.GPT import GPT\n",
    "from encoding.npp import zscore\n",
    "from decoding.Decoder import Decoder, Hypothesis\n",
    "from decoding.LanguageModel import LanguageModel\n",
    "from decoding.EncodingModel import EncodingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf35979",
   "metadata": {},
   "outputs": [],
   "source": [
    "stories = flatten_list(consts.STORIES)\n",
    "stimuli = stories\n",
    "modality = \"story\"\n",
    "goal = \"UTS09\"\n",
    "exclude = None\n",
    "references = [\"UTS02\", \"UTS03\"]#, \"UTS09\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba6b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reverse_corrs(goal, references, resp, cache = None):\n",
    "    \"\"\"select goal voxels by fitting reverse converters from references to goal\n",
    "    \"\"\"\n",
    "       \n",
    "    # fit converters from references to goal\n",
    "    rconverters = {}\n",
    "    for reference in references:\n",
    "        rvox = np.load(paths.EM % reference, allow_pickle = True).item()['voxels']\n",
    "        gresp_align = resp[goal]\n",
    "        rresp_align = resp[reference][:, rvox]\n",
    "        converter, _, _ = bootstrap_ridge(rresp_align, gresp_align, alphas = config.ALPHAS,\n",
    "                nboots = config.NBOOTS, chunklen = config.CHUNKLEN, use_corr = True, seed = 42)            \n",
    "        rconverters[reference] = (converter, rvox)        \n",
    "\n",
    "    # compare aligned responses across converters\n",
    "    stories = flatten_list(consts.STORIES[3:])\n",
    "    print(stories)\n",
    "    reverse_corrs = []\n",
    "    for story in stories:\n",
    "        rsim = []\n",
    "        for reference in references:\n",
    "            rvox = rconverters[reference][1]\n",
    "            rresp = get_resp(reference, [story], \"story\", stack = True, voxels = rvox)\n",
    "            rsim.append(zscore(rresp.dot(rconverters[reference][0])))\n",
    "        for c1 in range(len(rsim)):\n",
    "            for c2 in range(c1+1, len(rsim)):\n",
    "                reverse_corrs.append((rsim[c1] * rsim[c2]).mean(0))\n",
    "    return np.mean(reverse_corrs, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7fe9a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/naturalistic/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/opt/anaconda3/envs/naturalistic/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# load converter data\n",
    "resp_align = {}\n",
    "for subject in consts.SUBJECTS:\n",
    "    #resp_full = get_resp(subject, stories, \"story\", stack = True)\n",
    "    resp_align[subject] = get_resp(subject, stimuli, modality, stack = True)\n",
    "reverse_corrs = get_reverse_corrs(goal, [subject for subject in consts.SUBJECTS if subject != goal], resp_align)\n",
    "if exclude is not None:\n",
    "    exclude_mask = np.load(paths.ROI % (goal, exclude))\n",
    "    reverse_corrs[exclude_mask] = -1\n",
    "gvox = nsort(np.argsort(reverse_corrs)[-15000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56e5d158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train converters\n",
    "converters = {}\n",
    "for reference in references:\n",
    "    rvox = np.load(paths.EM % reference, allow_pickle = True).item()['voxels']\n",
    "    gresp_align = resp_align[goal][:, gvox]\n",
    "    rresp_align = resp_align[reference][:, rvox]\n",
    "    converter, _, _ = bootstrap_ridge(gresp_align, rresp_align, alphas = config.ALPHAS, \n",
    "            nboots = config.NBOOTS, chunklen = config.CHUNKLEN, use_corr = True, seed = 42)            \n",
    "    converters[reference] = (converter, gvox, rvox)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae844ba5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/Users/genevievelam/Documents/GitHub/ds003020/derivative/preprocessed_data/UTS09/wheretheressmoke.hf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# load responses\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m gresp \u001b[38;5;241m=\u001b[39m get_resp_test(goal, repeat \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# load models\u001b[39;00m\n\u001b[1;32m      5\u001b[0m em \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/Documents/GitHub/Cross-participant-semantic-decoding/decoding/utils_resp.py:27\u001b[0m, in \u001b[0;36mget_resp_test\u001b[0;34m(subject, voxels, repeat)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#subject_dir = os.path.join(DATA_TEST_DIR, \"test_response\", subject)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m resp_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(subject_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwheretheressmoke.hf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m hf \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(resp_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m resp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan_to_num(hf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindividual_repeats\u001b[39m\u001b[38;5;124m\"\u001b[39m][:\u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m voxels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/naturalistic/lib/python3.12/site-packages/h5py/_hl/files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/opt/anaconda3/envs/naturalistic/lib/python3.12/site-packages/h5py/_hl/files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, flags, fapl\u001b[38;5;241m=\u001b[39mfapl)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/Users/genevievelam/Documents/GitHub/ds003020/derivative/preprocessed_data/UTS09/wheretheressmoke.hf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "# load responses\n",
    "gresp = get_resp_test(goal, repeat = \"first\")\n",
    "\n",
    "# load models\n",
    "em = {}\n",
    "wr_data = []\n",
    "for reference in references:\n",
    "    wr_data.append(np.load(paths.WR % reference, allow_pickle = True).item())\n",
    "    em_data = np.load(paths.EM % reference, allow_pickle = True).item()\n",
    "    converter, gvox, rvox = converters[reference]\n",
    "    rresp = np.nan_to_num(zscore(gresp[:, gvox].dot(converter)))\n",
    "    em[reference] = EncodingModel(rresp, em_data[\"weights\"], em_data[\"noise_model\"], device = \"cuda\")\n",
    "    em[reference].set_shrinkage(config.NM_ALPHA)\n",
    "    tr_stats, word_stats = np.array(em_data[\"tr_stats\"]), em_data[\"word_stats\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dbf7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict word times\n",
    "with open(os.path.join(config.DATA_TRAIN_DIR, \"ROIs\", f\"{goal}.json\"), \"r\") as f:\n",
    "    roi_vox = json.load(f)\n",
    "starttime = -10\n",
    "word_rate = predict_word_rate(gresp, roi_vox, wr_data)\n",
    "word_times, tr_times = predict_word_times(word_rate, gresp, starttime = starttime)\n",
    "lanczos_mat = get_lanczos_mat(word_times, tr_times)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naturalistic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
